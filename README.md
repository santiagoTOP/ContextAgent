<div align="center">

# AgentZ: Agent from Zero

**A Context-Central Multi-Agent System Platform**

[![Notion Blog](https://img.shields.io/badge/Notion_Blog-000000?style=for-the-badge&logo=notion&logoColor=white)](https://www.notion.so/zhimengg/Agent-Z-27f111ca2fa080a28de4d76c49f0b08d?source=copy_link)
[![Documentation](https://img.shields.io/badge/Documentation-007ACC?style=for-the-badge&logo=markdown&logoColor=white)](YOUR_DOCS_LINK_HERE)
[![DeepWiki](https://img.shields.io/badge/DeepWiki-582C83?style=for-the-badge&logo=wikipedia&logoColor=white)](https://deepwiki.com/context-machine-lab/agentz)
[![WeChat](https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&logo=wechat&logoColor=white)](./assets/wechat.jpg)
[![Discord](https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/74my3Wkn)


</div>

AgentZ is a lightweight, context-central multi-agent systems framework designed for easy context engineering. It focuses on efficiently managing the context of each agent and binds all agents through simplified, centralized context operations. Unlike traditional multi-agent frameworks, AgentZ treats agents simply as LLMs with different contexts, eliminating unnecessary complexity. Built with a PyTorch-like API, developers can create sophisticated multi-agent systems with minimal code.


## üåü Features

- **üìã Context = Template + State**: Dynamic context management based on [Anthropic's blog](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents).
- **üîÄ Decoupled Agent Design**: Agent = LLM + Context. All agents are just LLMs with different contexts.
- **üé® PyTorch-Like Pipeline API**: Inherit `BasePipeline`, define async `run()`, use `@autotracing` decorator for tracing.
- **üåê Multi-LLM Support**: Works with OpenAI, Claude, Gemini, DeepSeek, and more.
- **üß© Modular Architecture**: Built on OpenAI Agents SDK with clear separation: context, agents, pipeline.
- **‚ö° Easy to Use & Customize**: Reuse pipelines with just a query; create new ones with familiar patterns.


## üì¢ News
- **[2025-10]** AgentZ is released now!


## üé¨ Demo


## üì¶ Installation

This project uses [uv](https://docs.astral.sh/uv/) for fast, reliable package management.

### Install uv

```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
```

See the [uv installation guide](https://docs.astral.sh/uv/getting-started/installation/) for more options.

### Setup Environment

```bash
# Clone the repository
git clone https://github.com/context-machine-lab/agentz.git
cd agentz

# Sync dependencies
uv sync
```

#### Configure API Keys

AgentZ requires API keys for LLM providers. Set up your environment in `.env` file:

```bash
# Copy the example environment file
cp .env.example .env
# Edit .env and add your API keys
```
See [.env.example](.env.example) for complete configuration options.


## üöÄ Quick Start

### Run Built-in Examples

Try out AgentZ with pre-configured example pipelines:

**Data Science Pipeline** - Automated ML pipeline for data analysis and model building:
```bash
uv run python -m examples.data_science
```

**Web Research Pipeline** - Search-based research with information extraction:
```bash
uv run python -m examples.web_researcher
```

### Basic API Pattern

Here's how to use AgentZ in your own code:

```python
from pipelines.data_scientist import DataScientistPipeline, DataScienceQuery

# Initialize pipeline with config
pipe = DataScientistPipeline("pipelines/configs/data_science.yaml")

# Create a query
query = DataScienceQuery(
    prompt="Analyze the dataset and build a predictive model",
    data_path="data/banana_quality.csv"
)

# Execute
pipe.run_sync(query)
```

### Web UI (Pipeline Manager)

Run the lightweight Flask web UI to submit and monitor pipelines with live logs:

```bash
uv run python frontend/app.py --host localhost --port 9090 --debug
```

Then open `http://localhost:9090` in your browser. The UI streams live status and panels from the running pipeline and lets you stop active runs.

## Steps to Build Your Own System

## üõ†Ô∏è Steps to Build Your Own System

AgentZ uses a **PyTorch-like API** for building multi-agent systems. Follow these steps to create your own pipeline:

#### Step 1 - Define Pipeline Class

Inherit from `BasePipeline` and call `super().__init__(config)`:

```python
from pipelines.base import BasePipeline
from pydantic import BaseModel

class YourPipeline(BasePipeline):
    def __init__(self, config):
        super().__init__(config)
        # Your initialization here
```

#### Step 2 - Create Context and Bind Agents

Create a centralized `Context`, get the LLM, and bind agents:

```python
from agentz.agent import ContextAgent
from agentz.context import Context

class YourPipeline(BasePipeline):
    def __init__(self, config):
        super().__init__(config)

        self.context = Context(["profiles", "states"])
        llm = self.config.llm.main_model

        # Manager agent example
        self.routing_agent = ContextAgent(self.context, profile="routing", llm=llm)

        # Tool agents example
        self.tool_agents = {
            "data_loader": ContextAgent(self.context, profile="data_loader", llm=llm),
            "analyzer": ContextAgent(self.context, profile="analyzer", llm=llm),
            # ... add more agents
        }
        self.context.state.register_tool_agents(self.tool_agents)
```

#### Step 3 - Define Async Run with @autotracing

Define your workflow in an async `run()` method:

```python
import asyncio
from pipelines.base import autotracing

class YourPipeline(BasePipeline):
    @autotracing()
    async def run(self, query: YourQuery):
        self.context.state.set_query(query)

        while self.iteration < self.max_iterations:
            self.iterate()

            # Call agents directly
            routing_result = await self.routing_agent(query)
```

#### Step 4 - Define Query Model and Execute

Create a Pydantic model and run your pipeline:

```python
class YourQuery(BaseModel):
    prompt: str
    # Add your custom fields

# Execute
pipe = YourPipeline("pipelines/configs/your_config.yaml")
query = YourQuery(prompt="Your task here")
result = pipe.run_sync(query)
```

#### Full Example Reference

See complete implementations in:
- **[examples/data_science.py](examples/data_science.py)** - Basic pipeline usage
- **[pipelines/data_scientist.py](pipelines/data_scientist.py)** - Full pipeline implementation reference
- **[Documentation](https://deepwiki.com/context-machine-lab/agentz)** - Detailed design guide


## üèóÔ∏è Architecture

AgentZ is organized around a **central conversation state** and a profile-driven agent system.
All agents are coordinated through a unified `Context` that manages iteration state and shared
information. The main components you will interact with are:

- **`pipelines/`** ‚Äì High-level orchestration with `BasePipeline` for workflow management and configuration loading.
- **`agentz/agent/`** ‚Äì `ContextAgent` class extending the agents framework with context awareness, plus runtime tracking and execution utilities.
- **`agentz/context/`** ‚Äì Central conversation state management (`ConversationState`, iteration tracking, context coordination).
- **`agentz/profiles/`** ‚Äì Profile definitions organized by domain (manager, data, web, debug, code, mcp) that define agent capabilities and behavior.
- **`agentz/tools/`** ‚Äì Tool implementations for data processing, web operations, and code execution.
- **`agentz/artifacts/`** ‚Äì Output generation and result formatting (artifact writing, reporting, terminal output).
- **`agentz/llm/`** ‚Äì LLM provider adapters and model configuration.
- **`agentz/mcp/`** ‚Äì Model Context Protocol integration for extended agent capabilities.
- **`agentz/utils/`** ‚Äì Utilities for configuration, parsing, and helper functions.
- **`examples/`** ‚Äì Example scripts showing end-to-end usage.
- **`frontend/`** ‚Äì Web UI for system interaction and monitoring.

```
agentz/
‚îú‚îÄ‚îÄ pipelines/
‚îÇ   ‚îú‚îÄ‚îÄ base.py               # BasePipeline with config management & helpers
‚îÇ   ‚îú‚îÄ‚îÄ configs/              # YAML configuration files for pipelines
‚îÇ   ‚îú‚îÄ‚îÄ data_scientist.py     # Data science pipeline implementation
‚îÇ   ‚îî‚îÄ‚îÄ web_researcher.py     # Web research pipeline implementation
‚îú‚îÄ‚îÄ agentz/
‚îÇ   ‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py          # ContextAgent class with context injection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tracker.py        # RuntimeTracker for execution monitoring
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ executor.py       # Execution utilities
‚îÇ   ‚îú‚îÄ‚îÄ context/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ context.py        # Context coordinator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conversation.py   # ConversationState and iteration management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_store.py     # Persistent data storage
‚îÇ   ‚îú‚îÄ‚îÄ profiles/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py           # Profile base class and loader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manager/          # Manager profiles (observe, routing, evaluate, writer)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/             # Data processing profiles
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web/              # Web research profiles
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ code/             # Code execution profiles
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ debug/            # Debug profiles
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mcp/              # MCP-based profiles
‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_tools/       # Data analysis and preprocessing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web_tools/        # Web searching and crawling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ code_tools/       # Code execution tools
‚îÇ   ‚îú‚îÄ‚îÄ artifacts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ artifact_writer.py # Output artifact generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reporter.py       # Result reporting
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terminal_writer.py # Terminal output formatting
‚îÇ   ‚îú‚îÄ‚îÄ llm/                  # LLM provider adapters
‚îÇ   ‚îú‚îÄ‚îÄ mcp/                  # MCP manager and server integration
‚îÇ   ‚îî‚îÄ‚îÄ utils/                # Config, parsers, helpers, printer
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ data_science.py       # Data science example
‚îÇ   ‚îî‚îÄ‚îÄ web_researcher.py     # Web research example
‚îî‚îÄ‚îÄ frontend/
    ‚îú‚îÄ‚îÄ app.py                # Web UI application
    ‚îú‚îÄ‚îÄ streaming_printer.py   # Real-time output streaming
    ‚îú‚îÄ‚îÄ static/               # Static assets
    ‚îî‚îÄ‚îÄ templates/            # HTML templates
```


## üìä Benchmarks

AgentZ's context-central design has been validated on multiple research benchmarks:

- **Data Science Tasks**: Efficient context sharing enables streamlined automated ML pipelines
- **Complex Reasoning**: Centralized state tracking improves multi-step reasoning coordination
- **Deep Research**: Search based complex reasoning and report generation

*Detailed benchmark results and comparisons coming soon.*


## üó∫Ô∏è Roadmap

- [x] Persistence Process - Stateful agent workflows
- [x] Experience Learning - Memory-based reasoning
- [x] Tool Design - Dynamic tool creation
- [ ] Frontend Support - Enhanced web UI for system interaction and monitoring
- [ ] MCP Support - Full Model Context Protocol integration for extended agent capabilities
- [ ] Claude Code Skill Support - Native integration with Claude Code environment
- [ ] Workflow RAG - Retrieval-augmented generation for complex workflows


## üìö Documentation

More details are available at [Documentation](https://deepwiki.com/context-machine-lab/agentz).


## üôè Acknowledgements

AgentZ's context-central design is inspired by the multi-agent systems research community and best practices in distributed state management. We are particularly grateful to:

- [OpenAI Agents SDK](https://github.com/openai/openai-agents-python) - For providing a lightweight, powerful framework for multi-agent workflows and the financial research agent example that demonstrates structured research patterns.
- [Youtu-Agent](https://github.com/TencentCloudADP/youtu-agent) - For its flexible agent framework architecture with open-source model support and tool generation capabilities.
- [agents-deep-research](https://github.com/qx-labs/agents-deep-research) - For its iterative deep research implementation showcasing multi-agent orchestration for complex reasoning tasks.

We thank the developers of these frameworks and the broader LLM community whose work informed this architecture.


## ü§ù Contributing

We welcome contributions! AgentZ is designed to be a community resource for multi-agent research. Please open an issue or submit a pull request.


## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


## üìñ Citation

If you use AgentZ in your research, please cite:

```bibtex
@misc{agentz2025,
  title={AgentZ: Agent from Zero},
  author={Zhimeng Guo, Hangfan Zhang, Siyuan Xu, Huaisheng Zhu, Teng Xiao, Jingyi Chen, Minhao Cheng},
  year={2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  url={https://github.com/context-machine-lab/agentz}
}
```